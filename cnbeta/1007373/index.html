<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="referrer" content="never">
	<title>MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来 - 罩妖塔</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta property="og:title" content="MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来" />
<meta property="og:description" content="会玩乐器的人在生活中简直自带光环！不过，学会一门乐器也真的很难，多少人陷入过从入门到放弃的死循环。但是，不会玩乐器，就真的不能演奏出好听的音乐了吗？最近，麻省理工（MIT）联合沃森人工智能实验室（MIT-IBM Watson AI Lab）共同开发出了一款AI模型Foley Music，它可以根据演奏手势完美还原乐曲原声！" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/n/cnbeta/1007373/" />
<meta property="article:published_time" content="2020-07-24T19:56:34+08:00" />
<meta property="article:modified_time" content="2020-07-24T19:56:34+08:00" />

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/n/css/style.css">
	
	<link rel="shortcut icon" href="/n/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/n" title="罩妖塔" rel="home">
				<div class="logo__title">罩妖塔</div>
				<div class="logo__tagline">师傅，别跑</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/n/cnbeta">
				
				<span class="menu__text">行业资讯</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2020-07-24T19:56:34&#43;08:00">July 24, 2020</time></div></div>
		</header>
		<div class="content post__content clearfix">
			<p>会玩乐器的人在生活中简直自带光环！不过，学会一门乐器也真的很难，多少人陷入过从入门到放弃的死循环。但是，不会玩乐器，就真的不能演奏出好听的音乐了吗？最近，麻省理工（MIT）联合沃森人工智能实验室（MIT-IBM Watson AI Lab）共同开发出了一款AI模型Foley Music，它可以根据演奏手势完美还原乐曲原声！</p>
<p><img src="https://static.cnbetacdn.com/thumb/article/2020/0724/4ada2bec18d4d54.gif" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>而且还是不分乐器的那种，小提琴、钢琴、尤克里里、吉他，统统都可以。</p>
<p><img src="https://static.cnbetacdn.com/thumb/article/2020/0724/b43f8db8d14ceb9.gif" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>只要拿起乐器，就是一场专业演奏会！如果喜欢不同音调，还可以对音乐风格进行编辑，A调、F调、G调均可。</p>
<p><img src="https://static.cnbetacdn.com/thumb/article/2020/0724/ca8f90d248f9229.png" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>这项名为《Foley Music：Learning to GenerateMusic from Videos》的技术论文已被ECCV 2020收录。</p>
<p>接下来，我们看看AI模型是如何还原音乐的？</p>
<p>会玩多种乐器的Foley Music</p>
<p>如同为一段舞蹈配乐需要了解肢体动作、舞蹈风格一样，为乐器演奏者配乐，同样需要知道其手势、动作以及所用乐器。</p>
<p>如果给定一段演奏视频，AI会自动锁定目标对象的身体关键点（Body Keypoints），以及演奏的乐器和声音。</p>
<p><img src="https://static.cnbetacdn.com/thumb/article/2020/0724/a2ab3453684766c.png" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>身体关键点：由AI系统中的视觉感知模块（Visual Perception Model）来完成。它会通过身体姿势和手势的两项指标来反馈。一般身体会提取25个关2D点，手指提起21个2D点。</p>
<p>乐器声音提取：采用音频表征模块（Audio Representation Model），该模块研究人员提出了一种乐器数字化接口（Musical Instrument Digital Interface，简称MIDI）的音频表征形式。它是Foley Music区别于其他模型的关键。</p>
<p>研究人员介绍，对于一个6秒中的演奏视频，通常会生成大约500个MIDI事件，这些MIDI事件可以轻松导入到标准音乐合成器以生成音乐波形。</p>
<p>在完成信息提取和处理后，接下来，视-听模块（Visual-Audio Model）将整合所有信息并转化，生成最终相匹配的音乐。</p>
<p>我们先来看一下它完整架构图：主要由视觉编码，MIDI解码和MIDI波形图输出三个部分构成。</p>
<p><img src="https://static.cnbetacdn.com/thumb/article/2020/0724/7ab1e4f11080ce5.png" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>视觉编码：将视觉信息进行编码化处理，并传递给转换器MIDI解码器。从视频帧中提取关键坐标点，使用GCN（Graph-CNN）捕获人体动态随时间变化产生的潜在表示。</p>
<p>MIDI解码器：通过Graph-Transfomers完成人体姿态特征和MIDI事件之间的相关性进行建模。Transfomers是基于编解码器的自回归生成模型，主要用于机器翻译。在这里，它可以根据人体特征准确的预测MIDI事件的序列。</p>
<p>MIDI输出：使用标准音频合成器将MIDI事件转换为最终的波形。</p>
<p>实验结果</p>
<p>研究人员证实Foley Music远优于现有其他模型。在对比试验中，他们采用了三种数据集对Foley Music进行了训练，并选择了9中乐器，与其它GAN-based、SampleRNN和WaveNet三种模型进行了对比评估。</p>
<p>其中，数据集分别为AtinPiano、MUSIC及URMP，涵盖了超过11个类别的大约1000个高质量的音乐演奏视频。乐器则为风琴，贝斯，巴松管，大提琴，吉他，钢琴，大号，夏威夷四弦琴和小提琴，其视频长度均为6秒。以下为定量评估结果：</p>
<p>可见，Foley Music模型在贝斯（Bass）乐器演奏的预测性能最高达到了72%，而其他模型最高仅为8%。</p>
<p><img src="https://static.cnbetacdn.com/article/2020/0724/21cb4df3404f11b.png" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>另外，从以下四个指标来看，结果更为突出：</p>
<p>正确性：生成的歌曲与视频内容之间的相关性。</p>
<p>噪音：音乐噪音最小。</p>
<p>同步性：歌曲在时间上与视频内容最一致。</p>
<p><img src="https://static.cnbetacdn.com/thumb/article/2020/0724/33d00654f6e2b7e.png" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>黄色为Foley Music模型，它在各项指标上的性能表现远远超过了其他模型，在正确性、噪音和同步性三项指标上最高均超过了0.6，其他最高不足0.4，且9种乐器均是如此。</p>
<p>另外，研究人员还发现，与其他基准系统相比，MIDI事件有助于改善声音质量，语义对齐和时间同步。</p>
<p>说明</p>
<p>GAN模型：它以人体特征为输入，通过鉴别其判定其姿态特征所产生的频谱图是真或是假，经过反复训练后，通过傅立叶逆变换将频谱图转换为音频波形。</p>
<p>SampleRNN：是无条件的端到端的神经音频生成模型，它相较于WaveNet结构更简单，在样本级层面生成语音要更快。</p>
<p>WaveNet：是谷歌Deepmind推出一款语音生成模型，在text-to-speech和语音生成方面表现很好。</p>
<p>另外，该模型的优势还在于它的可扩展性。MIDI表示是完全可解释和透明的，因此可以对预测的MIDI序列进行编辑，以生成AGF调不同风格音乐。 如果使用波形或者频谱图作为音频表示形式的模型，这个功能是不可实现的。</p>
<p><img src="https://static.cnbetacdn.com/thumb/article/2020/0724/4cc6df808dc72f3.png" alt="img:MIT联合沃森实验室团队推出最新AI 多种高难度乐器信手拈来"></p>
<p>最后研究人员在论文中表明，此项研究通过人体关键点和MIDI表示很好地建立视觉和音乐信号之间的相关性，实现了音乐风格的可拓展性。为当前研究视频和音乐联系拓展出了一种更好的研究路径。</p>
<p>以下为Youtube视频，一起来感受下AI音乐!</p>
<p><a href="https://www.youtube.com/watch?v=bo5UzyDB80E">https://www.youtube.com/watch?v=bo5UzyDB80E</a></p>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/n/cnbeta/1007377/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">五菱宏光侠概念车正式亮相：全新家族设计语言</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/n/cnbeta/1007397/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">7nm延迟6个月 英特尔的芯片也要外包了</p>
		</a>
	</div>
</nav>



			</div>
			<aside class="sidebar">
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/n/cnbeta/1009259/">恶意玩梗 抖音下架17万违规评论 部分帐号禁言30天</a></li>
			<li class="widget__item"><a class="widget__link" href="/n/cnbeta/1009243/">Google以垃圾信息为由屏蔽了具有历史意义的编程语言用户组</a></li>
			<li class="widget__item"><a class="widget__link" href="/n/cnbeta/1009249/">ofo这回真跑路了 欠款20亿，退押金等500年也没戏</a></li>
			<li class="widget__item"><a class="widget__link" href="/n/cnbeta/1009245/">Intel 10nm终于挺直腰杆：56核心秒掉AMD 64核心</a></li>
			<li class="widget__item"><a class="widget__link" href="/n/cnbeta/1009253/">金丝猴进村蹭吃蹭喝一周 村民：赶都赶不走</a></li>
		</ul>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2020 罩妖塔.
			
		</div>
	</div>
</footer>

	</div>
<script async defer src="/n/js/menu.js"></script>
</body>
</html>
